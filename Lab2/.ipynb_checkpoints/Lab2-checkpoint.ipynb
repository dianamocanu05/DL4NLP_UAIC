{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f26e446-2cab-4a8a-a423-e900761df834",
   "metadata": {},
   "source": [
    "# Lab 2 - Neural Networks applied in NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b548a2-757d-4c15-bbc2-b7b539a0a34a",
   "metadata": {},
   "source": [
    "@Author: Diana Mocanu\n",
    "\n",
    "@Date: 12.10.2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a959f27-7394-4873-9e79-e81d887282d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"The chicken is ready to eat.\",\n",
    "    \"John saw the chicken in the street.\",\n",
    "    \"The old chicken and ducks eat.\",\n",
    "    \"Join is an old ducks enthusiast.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaba94d-6323-4dc3-9884-94a7c4cc01c8",
   "metadata": {},
   "source": [
    "#### 1. Write a suitable constituency grammar, able to correctly parse all sentences, with all their senses. Use as inspiration the grammars discussed in class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142b99bf-638c-4b9e-ad2b-10529a113d9b",
   "metadata": {},
   "source": [
    "#### 2. Use existing modules to extract phrase structure trees for these sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "957a2e90-6b8b-4f0b-a2dd-f07b63fea722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag, RegexpParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "132d31e8-65dc-45a8-8fc3-69cb3fa670f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_pattern = \"\"\"\n",
    "    S: {<NP><VP>}\n",
    "    NP: {<DT>?<ADJ>?<NN>+}\n",
    "    VP: {<V><NP>}\n",
    "    DT: {<the>}\n",
    "    ADJ: {<ready>?<old>}\n",
    "    NN: {<chicken>?<John>?<ducks>?<street>?<enthusiast>}\n",
    "    P: {<in>?<and>}\n",
    "    V: {<is>?<eat>?<saw>}\n",
    "    ART: {<an>}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f52dec4a-138b-412c-8d17-6b2c3873da5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chicken is ready to eat.\n",
      "                        S                             \n",
      "   _____________________|________________              \n",
      "  |       |       |     |     |          NP           \n",
      "  |       |       |     |     |     _____|______       \n",
      "is/VBZ ready/JJ to/TO eat/VB ./. The/DT     chicken/NN\n",
      "\n",
      "\n",
      "\n",
      "John saw the chicken in the street.\n",
      "                        S                                            \n",
      "    ____________________|________________________________             \n",
      "   |        |      |    |          NP                    NP          \n",
      "   |        |      |    |     _____|______          _____|______      \n",
      "John/NNP saw/VBD in/IN ./. the/DT     chicken/NN the/DT     street/NN\n",
      "\n",
      "\n",
      "\n",
      "The old chicken and ducks eat.\n",
      "                         S                          \n",
      "   ______________________|______________________     \n",
      "  |      |      |        |      |      NP       NP  \n",
      "  |      |      |        |      |      |        |    \n",
      "The/DT old/JJ and/CC ducks/NNS ./. chicken/NN eat/NN\n",
      "\n",
      "\n",
      "\n",
      "Join is an old ducks enthusiast.\n",
      "                        S                               \n",
      "    ____________________|________________________        \n",
      "   |       |      |     |        |      |        NP     \n",
      "   |       |      |     |        |      |        |       \n",
      "Join/NNP is/VBZ an/DT old/JJ ducks/NNS ./. enthusiast/NN\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "tagged_sentences = [nltk.pos_tag(sentence) for sentence in tokenized_sentences]\n",
    "\n",
    "# Define a custom chunk parser using the custom_pattern\n",
    "custom_chunk_parser = RegexpParser(custom_pattern)\n",
    "\n",
    "# Parse the sentences and generate phrase structure trees\n",
    "parsed_trees = [custom_chunk_parser.parse(tagged_sentence) for tagged_sentence in tagged_sentences]\n",
    "\n",
    "# Display the phrase structure trees\n",
    "for sentence, parsed_tree in zip(sentences, parsed_trees):\n",
    "    print(sentence)\n",
    "    parsed_tree.pretty_print()\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd225b3a-cc3e-4ff6-b1d3-144da5f5e3e5",
   "metadata": {},
   "source": [
    "#### 3. Implement a dependency parser (using, for instance, spaCY, NLTK or Stanza) and parse the three sentences above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f1e876b-2453-4d4b-befa-8bd714b4222c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1674be2d-6198-47cd-a792-0ed7b502521f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chicken is ready to eat.\n",
      "The --det--> chicken\n",
      "chicken --nsubj--> is\n",
      "is --ROOT--> is\n",
      "ready --acomp--> is\n",
      "to --aux--> eat\n",
      "eat --xcomp--> ready\n",
      ". --punct--> is\n",
      "\n",
      "\n",
      "John saw the chicken in the street.\n",
      "John --nsubj--> saw\n",
      "saw --ROOT--> saw\n",
      "the --det--> chicken\n",
      "chicken --dobj--> saw\n",
      "in --prep--> saw\n",
      "the --det--> street\n",
      "street --pobj--> in\n",
      ". --punct--> saw\n",
      "\n",
      "\n",
      "The old chicken and ducks eat.\n",
      "The --det--> chicken\n",
      "old --amod--> chicken\n",
      "chicken --nsubj--> eat\n",
      "and --cc--> chicken\n",
      "ducks --conj--> chicken\n",
      "eat --ROOT--> eat\n",
      ". --punct--> eat\n",
      "\n",
      "\n",
      "Join is an old ducks enthusiast.\n",
      "Join --nsubj--> is\n",
      "is --ROOT--> is\n",
      "an --det--> enthusiast\n",
      "old --amod--> enthusiast\n",
      "ducks --compound--> enthusiast\n",
      "enthusiast --attr--> is\n",
      ". --punct--> is\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    print(sentence)\n",
    "    for token in doc:\n",
    "        print(f\"{token.text} --{token.dep_}--> {token.head.text}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b54365e-cc9f-44ec-9df0-051547574c37",
   "metadata": {},
   "source": [
    "#### 4. Describe an application which needs syntactic and/or dependency parsing. Explain  why, also providing concrete examples. (1/2 pag.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dbb9d8-6423-43c4-82e9-f9da6f92e21c",
   "metadata": {},
   "source": [
    "An application of syntactic/dependency parsing  is **machine translation**, translating from one language to another. Dependency parsing analyzes the grammatical structure of the source and target language. Cases in which dependency parsing is adding accuracy in the translation process include:\n",
    "1) Languages in which the the word order differs; example: English to German - a dependency parser will help recognize the part of the sentence, therefore making it easier to construct the right order of words.\n",
    "2) In the case of complex phrases, for example, translating a sentence with subordination, the dependency parser can correctly represent the relationship between clauses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
