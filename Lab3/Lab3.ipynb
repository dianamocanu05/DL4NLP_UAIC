{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18001aad-3ba0-48c2-80e1-b74c148f5c7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lab 3 - N-gram Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979c87a5-868b-4c58-8199-4e27f6aa5053",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1. Implement a generalized N-gram language model for the Romanian language using a smoothing technique at your choice, build on a corpus you collect from the web and lemmatize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3909f345-bd1b-439b-851f-d8ed2e286e04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "086f83b9-b43e-4df2-b492-b4c9406d2fbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import everygrams\n",
    "from nltk.lm import Laplace, NgramCounter\n",
    "from nltk import ngrams\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f8e45e18-5d2a-4d2c-9b5e-c2cf3be554d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ronec = load_dataset(\"ronec\")\n",
    "corpus = ronec[\"train\"]\n",
    "tokens_list = corpus[\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c19e35ba-d0c8-4ca1-83a6-205902ebc0a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-', 'Iohannis', ',', 'Klaus', 'Vacanță', 'Iohannis', '-', 'căruia', 'puțin', 'îi', 'pasă', 'că', '40%', 'din', 'populația', 'țării', 'trăiește', 'sub', 'limita', 'sărăciei', 'altfel', 'nu', 'ar', 'putea', 'să', 'susțină', 'sifonarea', 'profiturilor', 'de', 'către', 'multinaționalele', 'străine', 'și', 'ar', 'susține', 'impozitul', 'pe', 'venit', '-', 'Băsescu', ',', 'Traian', 'Băsescu', 'care', 'a', 'spus', 'că', 'aplicarea', 'unui', 'impozit', 'pe', 'venit', 'ține', 'de', '„', 'Paleoliticul', 'Financiar', '”', 'semn', 'că', 'joacă', 'în', 'continuare', 'cum', 'îi', 'cântă', 'Sistemul', 'și', 'că', 'i', 'se', 'fâlfâie', 'de', 'Sifonarea', 'Profiturilor', 'și', 'de', 'milioanele', 'de', 'români', 'săraci']\n"
     ]
    }
   ],
   "source": [
    "print(tokens_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4664ebae-6f5c-4b84-b481-c5941e74b14c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flattened_tokens = [token for tokens in tokens_list for token in tokens]\n",
    "lemmatized_tokens = [WordNetLemmatizer().lemmatize(token) for token in flattened_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6feb81ca-60c3-4099-8d19-89d9c91c902c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 2 \n",
    "\n",
    "n_grams = list(ngrams(lemmatized_tokens, n))\n",
    "lm = Laplace(order=n)\n",
    "lm.fit([n_grams], vocabulary_text=lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28f7006-815c-4926-aabc-ae4c2f3be156",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2. Compute the probability of a new Romanian sentence, given at input, using the n-gram model you developed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f494080e-fb35-46cc-be9e-1713d87d73b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of the sentence: 1.0221789423720594e-22\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Astazi va ninge la munte.\"\n",
    "tokens = [WordNetLemmatizer().lemmatize(token) for token in word_tokenize(sentence)]\n",
    "\n",
    "n = 2  \n",
    "new_ngrams = list(ngrams(tokens,n))\n",
    "\n",
    "sentence_probability = 1.0  \n",
    "for ngram in new_ngrams:\n",
    "    probability = lm.score(ngram[-1], ngram[:-1])\n",
    "    sentence_probability *= probability\n",
    "\n",
    "print(\"Probability of the sentence:\", sentence_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf089eaa-4875-41c7-8373-5594da454a78",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.Use a pre-trained neural language model to predict the next two words after a sequence of 4 words given as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc9cf44-9bb4-4e55-b2bd-6b349dfdacd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cd646705-127a-47db-965e-83840dc436f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_text = \"I am going to\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b66cb952-fcd6-4126-a057-ef3d127f361d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexed_tokens = tokenizer.encode(input_text)\n",
    "tokens_tensor = torch.tensor([indexed_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7f82a309-6618-43ba-a518-0d30a3349606",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I am going to be a\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "     for _ in range(0,2):\n",
    "        outputs = model(tokens_tensor)\n",
    "        predictions = outputs[0]\n",
    "        predicted_index = torch.argmax(predictions[0, -1, :]).item()\n",
    "        indexed_tokens.append(predicted_index)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        \n",
    "predicted_text = tokenizer.decode(indexed_tokens)\n",
    "\n",
    "print(predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6b697e-7591-420d-991a-18ecffdcfec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
