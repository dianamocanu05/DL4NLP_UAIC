{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eea12b2-2e97-4d51-aa9e-0d1d1f3bd36b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lab 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd48e1a-b69c-404f-9823-9b18d232c932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca9b6c05-4901-4e9e-b3a6-dd66d6347b26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\diana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')  \n",
    "nltk.download('stopwords') \n",
    "nltk.download('wordnet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8c134ba-77be-4146-8f84-790c3de26101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wiki_wiki = wikipediaapi.Wikipedia(language = \"en\", user_agent = \"python-requests/x\")\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9486930f-dac6-47fc-ab6b-f00ce74ab8ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_document(article_title):\n",
    "    page = wiki_wiki.page(article_title)\n",
    "    if page.exists():\n",
    "        article_content = page.text\n",
    "        return article_content\n",
    "    else:\n",
    "        raise Exception(f\"The article '{article_title}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7001e19c-c69e-4fdb-8986-b293af319875",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geography_articles = [\"Romania\", \"Continental climate\", \"Central Asia\", \"Desert\", \"Polar regions of Earth\"] \n",
    "history_articles = [\"World War I\", \"Ottoman Empire\", \"Central Powers\", \"Carol I of Romania\", \"Alexandru Ioan Cuza\"]\n",
    "music_articles = [\"Octave\", \"Solf√®ge\", \"Ludwig van Beethoven\", \"Kapellmeister\", \"Wolfgang Amadeus Mozart\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db253967-30a0-46cb-80e9-aa687d5e2635",
   "metadata": {},
   "source": [
    "#### 1. Use text preprocessing techniques (stemming/lematization, stop words removal) and create the bag-of-words and TF-IDF vectorizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06103669-5209-4529-8eaa-9fa3e4f517fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text, use_stemming=True, use_lemmatization=True):\n",
    "    # tokenization \n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word.lower() not in stop_words]\n",
    "    \n",
    "    # stemming\n",
    "    if use_stemming:\n",
    "        words = [stemmer.stem(word) for word in words]\n",
    "    # lemmatization\n",
    "    if use_lemmatization:\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    cleaned_text = ' '.join(words)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9430025-422c-45bf-bda3-e1dc9410117a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract and preprocess\n",
    "all_documents = []\n",
    "for article_title in geography_articles + history_articles + music_articles:\n",
    "    article_content = extract_document(article_title)\n",
    "    if article_content:\n",
    "        preprocessed_text = preprocess_text(article_content)\n",
    "        all_documents.append(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f018718-f125-4fc3-a5d3-7e7488b60f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bag-of-words and TF-IDF vectorizations\n",
    "count_vectorizer = CountVectorizer()\n",
    "bag_of_words = count_vectorizer.fit_transform(all_documents)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(all_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58987f6-68b2-4ec8-87d1-4965b4854b84",
   "metadata": {},
   "source": [
    "#### 2.Use Latent Semantic Analysis with SVD for a) the bag-of-words encoding and b) the TF-IDF encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98529be-749d-496c-88be-bbf503da39c4",
   "metadata": {},
   "source": [
    "a) bag-of-words encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0efc57c0-cfea-43f1-a25c-70927008e80f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lsa_bow = TruncatedSVD(n_components=3)  \n",
    "lsa_bow_result = lsa_bow.fit_transform(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf1d4f49-9b61-4cc7-aea5-504e196bcbd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.65013861e+02 -4.32573724e+01  6.90101908e+01]\n",
      " [ 1.32832114e+01 -5.90949998e+00  1.72863779e+01]\n",
      " [ 1.35207719e+02 -2.48120980e+01  1.67922332e+02]\n",
      " [ 8.00844425e+01 -3.33574907e+01  1.85052850e+02]\n",
      " [ 6.18165012e+00 -1.18365002e+00  8.37231661e+00]\n",
      " [ 4.25490919e+02 -2.45776777e+02 -1.19155890e+02]\n",
      " [ 4.16310925e+02  3.02458854e+02 -3.57257638e+01]\n",
      " [ 1.21040912e+02 -3.42785364e+01 -3.73052332e+01]\n",
      " [ 5.77522035e+01 -1.68771669e+01  7.73838422e+00]\n",
      " [ 1.92717898e+01 -2.25029270e+00  5.23922018e+00]\n",
      " [ 8.63692660e+00 -2.09371484e-01  8.69551550e+00]\n",
      " [ 2.36154534e+01  4.92771005e-01  1.74422869e+01]\n",
      " [ 8.62066262e+01 -2.77221727e+01  1.92753693e+02]\n",
      " [ 1.29414525e+01 -3.34067495e+00  1.29122291e+01]\n",
      " [ 4.38779007e+01 -1.14100649e+01  7.01113022e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(lsa_bow_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f58c69c-20e9-458e-a78d-d536504aea5f",
   "metadata": {},
   "source": [
    "b) TF-IDF encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "261e46de-7bc3-4d86-ad69-103b6d987ba6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.6515496  -0.04927958 -0.21448861]\n",
      " [ 0.1125157   0.03260077  0.36035918]\n",
      " [ 0.3918041   0.00259362  0.39408612]\n",
      " [ 0.1970676   0.09197144  0.45561148]\n",
      " [ 0.13892616  0.04860623  0.47196891]\n",
      " [ 0.74652064 -0.16752997  0.114366  ]\n",
      " [ 0.61196719 -0.10304951  0.11263035]\n",
      " [ 0.71082036 -0.24616751  0.15371572]\n",
      " [ 0.59348185 -0.08079813 -0.43573194]\n",
      " [ 0.43790626 -0.02798495 -0.44519833]\n",
      " [ 0.08140569  0.32784776  0.08004793]\n",
      " [ 0.16098901  0.38550554  0.08723378]\n",
      " [ 0.22118518  0.5973567  -0.06482254]\n",
      " [ 0.15435439  0.51884501 -0.08225064]\n",
      " [ 0.19623109  0.63648751 -0.0718288 ]]\n"
     ]
    }
   ],
   "source": [
    "lsa_tfidf = TruncatedSVD(n_components=3) \n",
    "lsa_tfidf_result = lsa_tfidf.fit_transform(tfidf_matrix)\n",
    "print(lsa_tfidf_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d94edb1-1c11-46e1-8471-7c22481ac2eb",
   "metadata": {},
   "source": [
    "#### 3. Use Non-negative matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35e8905d-51bd-4f21-9010-f25e6c369233",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.20029225e-01 3.59033932e-01 9.36174822e-01]\n",
      " [9.41094653e-03 1.51659810e-02 2.03588871e-01]\n",
      " [6.22427599e-02 0.00000000e+00 2.19035047e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.87116329e+00]\n",
      " [4.10204244e-03 8.95492026e-03 9.50354588e-02]\n",
      " [2.50700588e+00 8.95586010e-02 2.49244314e-02]\n",
      " [2.50706208e+00 0.00000000e+00 0.00000000e+00]\n",
      " [7.25547037e-01 0.00000000e+00 0.00000000e+00]\n",
      " [2.74208214e-01 1.57490014e-01 1.52218841e-01]\n",
      " [8.62321671e-02 8.47707389e-02 5.72963922e-02]\n",
      " [2.26338375e-02 1.75067518e-01 3.29584207e-02]\n",
      " [7.94465168e-02 3.36854637e-01 8.01072243e-02]\n",
      " [0.00000000e+00 5.65139906e+00 0.00000000e+00]\n",
      " [3.50916662e-02 3.65285622e-01 1.57341139e-02]\n",
      " [5.04796120e-02 1.89874917e+00 5.74468135e-02]]\n"
     ]
    }
   ],
   "source": [
    "# bag-of-words encoding\n",
    "nmf_bow = NMF(n_components=3, init='random', random_state=0)\n",
    "nmf_bow_result = nmf_bow.fit_transform(bag_of_words)\n",
    "\n",
    "print(nmf_bow_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c0508be-aee0-45c8-b994-bac7ae2a22f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02030037 0.15058672 0.00126084]\n",
      " [0.0128651  0.00041327 0.00212605]\n",
      " [0.04428451 0.00531392 0.00387212]\n",
      " [0.02048417 0.00124481 0.00996292]\n",
      " [0.01651073 0.         0.00337802]\n",
      " [0.08775876 0.00892126 0.0012241 ]\n",
      " [0.07322559 0.00112287 0.00332864]\n",
      " [0.09210914 0.         0.        ]\n",
      " [0.00701923 0.17285355 0.        ]\n",
      " [0.         0.15613746 0.        ]\n",
      " [0.         0.         0.04161704]\n",
      " [0.00251553 0.00025967 0.05164886]\n",
      " [0.00048959 0.00379173 0.07993362]\n",
      " [0.         0.         0.06833608]\n",
      " [0.         0.         0.08367664]]\n"
     ]
    }
   ],
   "source": [
    "# bag-of-words encoding\n",
    "nmf_tfidf = NMF(n_components=3, init='random', random_state=0)  \n",
    "nmf_tfidf_result = nmf_tfidf.fit_transform(tfidf_matrix)\n",
    "\n",
    "print(nmf_tfidf_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bbc01d-9120-4dd4-bc21-26cbecc42a80",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4. Use LDA (Latent Dirichlet Allocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfcaf58d-c0f7-4d51-9951-3d2d6be3a51f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.73879484e-01 5.82113696e-05 3.26062305e-01]\n",
      " [2.14623296e-04 9.99567369e-01 2.18007273e-04]\n",
      " [6.51030766e-05 9.13368465e-01 8.65664322e-02]\n",
      " [6.32030556e-05 9.99870219e-01 6.65775809e-05]\n",
      " [8.33838848e-04 9.98274697e-01 8.91463801e-04]\n",
      " [3.30588616e-05 3.32203818e-05 9.99933721e-01]\n",
      " [4.01336314e-05 3.94124284e-05 9.99920454e-01]\n",
      " [1.63962097e-04 1.66687662e-04 9.99669350e-01]\n",
      " [7.99167000e-02 1.69485297e-04 9.19913815e-01]\n",
      " [4.01181752e-04 3.69447324e-04 9.99229371e-01]\n",
      " [9.99059517e-01 4.72484613e-04 4.67998709e-04]\n",
      " [9.99541848e-01 2.26015600e-04 2.32135996e-04]\n",
      " [9.99870086e-01 6.33257629e-05 6.65886519e-05]\n",
      " [9.99389822e-01 2.93721121e-04 3.16456819e-04]\n",
      " [9.99786555e-01 1.04006415e-04 1.09438415e-04]]\n"
     ]
    }
   ],
   "source": [
    "lda_bow = LatentDirichletAllocation(n_components=3, random_state=0)\n",
    "lda_bow_result = lda_bow.fit_transform(bag_of_words)\n",
    "print(lda_bow_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd48b52b-3854-440b-b6ee-e0650262ea87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01322952 0.0132161  0.97355438]\n",
      " [0.02702501 0.94501093 0.02796406]\n",
      " [0.01847919 0.01879002 0.96273079]\n",
      " [0.02132493 0.95581157 0.0228635 ]\n",
      " [0.0369273  0.92404078 0.03903192]\n",
      " [0.01367734 0.01357951 0.97274316]\n",
      " [0.01685997 0.01659923 0.9665408 ]\n",
      " [0.02169244 0.02164742 0.95666014]\n",
      " [0.02081244 0.0205949  0.95859266]\n",
      " [0.02199317 0.02180831 0.95619852]\n",
      " [0.90828468 0.0453578  0.04635753]\n",
      " [0.94365216 0.02751833 0.02882951]\n",
      " [0.95612485 0.02127617 0.02259898]\n",
      " [0.94361264 0.02750418 0.02888317]\n",
      " [0.95082869 0.02388471 0.0252866 ]]\n"
     ]
    }
   ],
   "source": [
    "lda_tfidf = LatentDirichletAllocation(n_components=3, random_state=0)\n",
    "lda_tfidf_result = lda_tfidf.fit_transform(tfidf_matrix)\n",
    "print(lda_tfidf_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bb92ec-4cb5-4843-b66f-0eddd57b76c7",
   "metadata": {},
   "source": [
    "#### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acbe29d9-b042-4d33-bdbe-5d9f9b4f4fe9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: beethoven mozart music romania work year romanian includ first compos\n",
      "Topic #1: desert central asia region border water climat kazakhstan asian area\n",
      "Topic #2: ottoman war empir german state power germani world 000 forc\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 10 \n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_words_idx = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        top_words = [feature_names[i] for i in top_words_idx]\n",
    "        print(f\"Topic #{topic_idx}: {' '.join(top_words)}\")\n",
    "\n",
    "print_top_words(lda_bow, count_vectorizer.get_feature_names_out(), n_top_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
